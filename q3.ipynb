{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "import re\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"Q3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to append every txt file\n",
    "\n",
    "def getTxt(path):\n",
    "    main_corpus = PlaintextCorpusReader(path, '.*')\n",
    "\n",
    "    # list of files\n",
    "    corpus_list = []\n",
    "\n",
    "    for root, dirs, filenames in os.walk(PATH):\n",
    "        for f in filenames:\n",
    "            if f.endswith('.txt'):\n",
    "                    corpus_list.append(f)\n",
    "    \n",
    "     # combine sentences from all corpus into one list\n",
    "    documents = []\n",
    "    for corpus in corpus_list:\n",
    "        corpus = main_corpus.raw(corpus)\n",
    "        d = corpus.strip().split('\\n')\n",
    "        for s in d:\n",
    "            s = s.strip()\n",
    "            s = ' '.join(s.split())\n",
    "            documents.append(s)\n",
    "            \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### abstract ###',\n",
       " 'AIMX we test in the context of a dictator game the proposition that individuals may experience a self-control conflict between the temptation to act selfishly and the better judgment to act pro-socially',\n",
       " 'OWNX we manipulated the likelihood that individuals would identify self-control conflict, and we measured their trait ability to implement self-control strategies',\n",
       " 'OWNX our analysis reveals a positive and significant correlation between trait self-control and pro-social behavior in the treatment where we expected a relatively high likelihood of conflict identification-but not in the treatment where we expected a low likelihood',\n",
       " 'OWNX the magnitude of the effect is of economic significance']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_labeled = getTxt(PATH)\n",
    "txt_labeled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split labels and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we test in the context of a dictator game the proposition that individuals may experience a self-control conflict between the temptation to act selfishly and the better judgment to act pro-socially', 'we manipulated the likelihood that individuals would identify self-control conflict, and we measured their trait ability to implement self-control strategies', 'our analysis reveals a positive and significant correlation between trait self-control and pro-social behavior in the treatment where we expected a relatively high likelihood of conflict identification-but not in the treatment where we expected a low likelihood', 'the magnitude of the effect is of economic significance']\n",
      "['AIMX', 'OWNX', 'OWNX', 'OWNX']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for txt in txt_labeled:\n",
    "    # check for headers containing ###\n",
    "    if txt[:3] != '###':\n",
    "        # get sentence\n",
    "        sentence = txt[5:]\n",
    "        label = txt[:4]\n",
    "\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "\n",
    "print(sentences[:4])\n",
    "print(labels[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/tugus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decontracting words in english so it have better meaning\n",
    "def decontract(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentences, stopwords):\n",
    "  preprocessed_sentences = []\n",
    "  for sentence in sentences:\n",
    "    decontract(sentence)\n",
    "    # removing extra spaces and numbers\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    # removing non alphabels\n",
    "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
    "    preprocessed_sentences.append(sentence.strip())\n",
    "  return preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test context dictator game proposition individuals may experience self control conflict temptation act selfishly better judgment act pro socially', 'manipulated likelihood individuals would identify self control conflict measured trait ability implement self control strategies', 'analysis reveals positive significant correlation trait self control pro social behavior treatment expected relatively high likelihood conflict identification treatment expected low likelihood', 'magnitude effect economic significance']\n",
      "['AIMX', 'OWNX', 'OWNX', 'OWNX']\n"
     ]
    }
   ],
   "source": [
    "sentences_processed = clean_sentence(sentences, stops)\n",
    "print(sentences_processed[:4])\n",
    "print(labels[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentences\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif(x, y, estimator):\n",
    "    y_pred = estimator.predict(x)\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3117, 4010)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vector = vectorizer.fit_transform(X)\n",
    "X_vector = X_vector.toarray()\n",
    "X_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labeled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vector, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierSVM = svm.SVC()\n",
    "classifierSVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AIMX       0.78      0.60      0.68        42\n",
      "        BASE       0.50      0.14      0.22         7\n",
      "        CONT       0.65      0.33      0.44        33\n",
      "        MISC       0.88      0.95      0.92       371\n",
      "        OWNX       0.82      0.83      0.82       171\n",
      "\n",
      "    accuracy                           0.85       624\n",
      "   macro avg       0.73      0.57      0.62       624\n",
      "weighted avg       0.84      0.85      0.84       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif(X_test, y_test, classifierSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierRF = RandomForestClassifier()\n",
    "classifierRF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AIMX       0.71      0.64      0.67        42\n",
      "        BASE       0.67      0.86      0.75         7\n",
      "        CONT       0.52      0.42      0.47        33\n",
      "        MISC       0.90      0.91      0.91       371\n",
      "        OWNX       0.79      0.81      0.80       171\n",
      "\n",
      "    accuracy                           0.84       624\n",
      "   macro avg       0.72      0.73      0.72       624\n",
      "weighted avg       0.84      0.84      0.84       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif(X_test, y_test, classifierRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierDT = DecisionTreeClassifier()\n",
    "classifierDT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AIMX       0.66      0.69      0.67        42\n",
      "        BASE       0.43      0.86      0.57         7\n",
      "        CONT       0.40      0.52      0.45        33\n",
      "        MISC       0.90      0.88      0.89       371\n",
      "        OWNX       0.81      0.75      0.78       171\n",
      "\n",
      "    accuracy                           0.82       624\n",
      "   macro avg       0.64      0.74      0.67       624\n",
      "weighted avg       0.83      0.82      0.82       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif(X_test, y_test, classifierDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
